{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 22:05:11.102748: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-29 22:05:11.102783: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-29 22:05:11.104705: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-29 22:05:11.113473: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 22:05:13.556314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.inference import SNPE, SNLE, prepare_for_sbi\n",
    "from sbi.utils.get_nn_models import posterior_nn, likelihood_nn\n",
    "from sbi.neural_nets.embedding_nets import FCEmbedding\n",
    "from CosmoFuse.visualisation import make_corner_plot\n",
    "import wandb\n",
    "\n",
    "device=\"cuda:0\"\n",
    "rng = np.random.default_rng(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_train=161967, N_val=20000, N_test=20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_138936/263260566.py:49: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  prior = utils.BoxUniform(low=torch.tensor([y.min(axis=0)]), high=torch.tensor([y.max(axis=0)]), device=device)\n",
      "/home/moon/dgebauer/anaconda3/envs/sbi/lib/python3.11/site-packages/sbi/utils/torchutils.py:27: UserWarning: GPU was selected as a device for training the neural network. Note that we expect no significant speed ups in training for the default architectures we provide. Using the GPU will be effective only for large neural networks with operations that are fast on the GPU, e.g., for a CNN or RNN `embedding_net`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "min_scale = 6 \n",
    "\n",
    "theta = np.load('../data/run2/theta.npy')[:,:2] # [Om, s8, w, n_s, Ob, H0]\n",
    "\n",
    "xip = np.load('../data/run2/xip.npy')\n",
    "xim = np.load('../data/run2/xim.npy')\n",
    "xi = np.concatenate((xip[:,:,min_scale:,None], xim[:,:,min_scale:,None]), axis=3)\n",
    "xi_flat = xi.reshape(xi.shape[0], -1)\n",
    "\n",
    "\n",
    "base_path_fiducial = '/e/ocean1/users/dgebauer/sbi/measurements/fiducial/'\n",
    "xip_fiducial = np.load(base_path_fiducial + 'xip.npy').reshape(800, 10, 15)[:,:,min_scale:].reshape(800,-1)\n",
    "xim_fiducial = np.load(base_path_fiducial + 'xim.npy').reshape(800, 10, 15)[:,:,min_scale:].reshape(800,-1)\n",
    "xi_fiducial = np.concatenate((xip_fiducial, xim_fiducial), axis=1)\n",
    "\n",
    "\n",
    "cov = np.cov(xi_fiducial.T)\n",
    "noise = rng.multivariate_normal(np.zeros(xi_fiducial.shape[1]), cov, xi_flat.shape[0])\n",
    "xi_flat += noise\n",
    "\n",
    "\n",
    "x = np.load('../data/likelihood_transformed/x.npy')\n",
    "\n",
    "y = theta\n",
    "\n",
    "val_inds = np.random.choice(np.arange(x.shape[0]), size=int(x.shape[0]*0.1), replace=False)\n",
    "test_inds = np.random.choice(np.arange(x.shape[0]), size=int(x.shape[0]*0.1), replace=False)\n",
    "y_val = y[val_inds]\n",
    "y_test = y[test_inds]\n",
    "y_train = np.delete(y, [val_inds, test_inds], axis=0)\n",
    "x_val = x[val_inds]\n",
    "x_test = x[test_inds]\n",
    "x_train = np.delete(x, [val_inds, test_inds], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
    "x_val = torch.tensor(x_val, dtype=torch.float32).to(device)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "y_test = np.concatenate([y_test[:,0, None], (y_test[:,1]*np.sqrt(y_test[:,0]/0.3))[:,None], y_test[:,1, None]], axis=1)\n",
    "\n",
    "print(f\"N_train={x_train.shape[0]}, N_val={x_val.shape[0]}, N_test={x_test.shape[0]}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "param_names = [r'$\\Omega_m$', r'$\\sigma_8$', r'$S_8$']\n",
    "prior = utils.BoxUniform(low=torch.tensor([y.min(axis=0)]), high=torch.tensor([y.max(axis=0)]), device=device)\n",
    "_, prior = prepare_for_sbi(lambda foo: 0, prior)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 66"
     ]
    }
   ],
   "source": [
    "density_estimator_custom = likelihood_nn(model=\"maf\", num_transforms=4, hidden_features=64, num_blocks=3, device=device)\n",
    "inference = SNLE(density_estimator=density_estimator_custom, prior=prior, device=device)\n",
    "density_estimator = inference.append_simulations(y_train, x_train).train(show_train_summary=True, stop_after_epochs=20, training_batch_size=100, learning_rate=1e-4)\n",
    "posterior = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011cb2ba3c9c48b396ac385f18d51a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drawing 1000000000 posterior samples:   0%|          | 0/1000000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_ind = np.array([np.linalg.norm(x+y) for (x,y) in np.abs(y_test[:,(0,2)]-np.array([[0.26, 0.84]]))]).argmin()\n",
    "sample = posterior.sample((10000000,), x=x_test[eval_ind]).detach().cpu().numpy()\n",
    "sample = np.concatenate([sample[:,0, None], (sample[:,1]*np.sqrt(sample[:,0]/0.3))[:,None], sample[:,1, None]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "param_names = [r'$\\Omega_m$', r'$S_8$', r'$\\sigma_8$']\n",
    "\n",
    "_ = make_corner_plot(sample, theta_obs=y_test[eval_ind], param_names=param_names, smooth=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
